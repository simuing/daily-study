## 3.4 상황에 따라 자동으로 스케일 조정하기

엔지니어가 파드의 자원 사용량을 예의 주시하고 있다가 사용량이 급증하기 시작할 때 빠르게 디플로이먼트를 스케일해 주는 작업은 기술적으로 어렵지 않지만 매일 모니터링하는 것은 매우 비효율적이다.

다행히도 쿠버네티스에 모니터링과 스케일링을 자동으로 해주는 오브젝트가 있는데, 이를 오토스케일러(autoscaler)라고 부른다. 특히 자원 사용량에 따라 파드의 숫자를 조절해 주는 오브젝트를 HPA(Horizontal Pod Autoscaler)라고 한다.

오토스케일러의 동작을 확인하기 위해서 `my-stress` 디플로이먼트를 일부 수정한다.

```yaml
# chapter3/my-stress-03.yaml
...(중략)...
    spec:
      containers:
      - name: stress-generator
        image: stress:1.0.0
        args: ["--cpu", "2", "--vm", "1", "--vm-bytes", "500M", "--timeout", "600s"]
        resources:
          requests:
            cpu: "500m"
            memory: "1000Mi"
          limits:
            cpu: "1000m"
            memory: "2000Mi"
```

그리고 오토스케일을 담당할 HPA를 다음과 같이 만들어 준다.

```yaml
# chapter3/stress-hpa.yaml
apiVersion: autoscaling/v1
kind: HorizontalPodAutoscaler # HPA 오브젝트 선언
metadata:
  name: stress-hpa
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: my-stress
  minReplicas: 1 # 최소 복제 수
  maxReplicas: 4 # 최대 복제 수
  targetCPUUtilizationPercentage: 50 # 이상적인 CPU 사용률
```

생성한 HPA를 쿠버네티스에 적용해 준다.
```
$ kubectl apply -f stress-hpa.yaml 
horizontalpodautoscaler.autoscaling/stress-hpa created
```

그리고 작성한 `my-stress` 디플로이먼트를 적용해준다.
```
$ kubectl apply -f my-stress-03.yaml
deployment.apps/my-stress created
```

각 파드는 기동 후 60초를 기다린 뒤 CPU 로드를 발생시킨다. 최초에는 replicas를 2개로 설정했으므로 2개의 파드가 생성된다. 잠시 뒤 조회해 보면 HPA가 현재 부하를 측정하고 있음을 알 수 있다.
```
(before 60s)
$ kubectl top pods
NAME                         CPU(cores)   MEMORY(bytes)   
my-stress-697f898888-k48z2   1000m        61Mi            
my-stress-697f898888-vfwhs   1000m        22Mi            
$ kubectl get hpa
NAME         REFERENCE              TARGETS    MINPODS   MAXPODS   REPLICAS   AGE
stress-hpa   Deployment/my-stress   196%/50%   1         4         2          4m8s
```
```
(after 60s)
$ kubectl top pods
NAME                         CPU(cores)   MEMORY(bytes)   
my-stress-697f898888-d9v8k   972m         233Mi           
my-stress-697f898888-k48z2   969m         128Mi           
my-stress-697f898888-vfwhs   976m         443Mi           
my-stress-697f898888-z5t56   983m         423Mi        
$ kubectl get hpa
NAME         REFERENCE              TARGETS    MINPODS   MAXPODS   REPLICAS   AGE
stress-hpa   Deployment/my-stress   194%/50%   1         4         4          5m10s
```

HPA의 동작은 엔지니어가 파드를 스케일하는 동작과 매우 유사하다. HPA는 지속적으로 파드의 자원 사용량을 모니터링하면서 최적의 파드 숫자를 결정하고, replicas를 조정하여 대응한다.

실제로 목표하는 `replicas`는 다음과 같은 공식으로 결정한다.

```
목표 파드 수 = 현재 파드 수 X (현재 자원 사용량 / 목표 자원 사용량)
```

위의 코드에서 HPA를 정의할 때 `targtCPUUtilizationPercentage: 50`이라고 명해준 것은, 파드가 50% 정도의 CPU를 사용하는 것이 이상적이라는 뜻이다. 현재 2개의 파드의 CPU 사용률이 모두 60%라면 공식에 따라 `replicas`는 다음과 같이 결정된다.
```
목표 파드 수 = 2 X (60 / 50) = 2.4
```

쿠버네티스는 오토스케일러에 의해 파드의 숫자를 결정할 때 항상 결과를 올림한다. 따라서 쿠버네티스는 파드를 3개로 조정한다.

만약 부하가 줄어들어서 파드가 평균 20% 정도의 CPU 만 사용한다면 파드 숫자는 다음과 같이 바뀐다.
```
목표 파드 수 = 3 X (20 / 50) = 1.2
```

따라서 파드는 2개로 줄어든다. 쿠버네티스는 이런 동작을 반복하며 최적의 파드 숫자를 유지하도록 노력한다.

<br/>

#### 오토스케일러의 흔들림 억제 동작

오토스케일러 때문에 파드의 숫자가 급격히 변동하는 흔들림(thrashing) 현상을 억제하기 위해서 쿠버네티스는 몇 가지 파라미터들을 제공한다.

예를 들어 쿠버네티스는 기본적으로 10%의 자원 사용량 변동은 스케일링을 발생시키지 않도록 용인해 주며, 어떤 형태로든 스케일 다운이 일어났다면 5분간은 추가적인 스케일 다운을 하지 않는다. 또한 새로 추가된 파드는 30초간 메트릭 수집 대상에서 제외하여 자원 사용량의 평균값이 왜곡되는 것을 막아준다.