## 3.2 파드 자원 사용량 정의하고 스케일 업하기

쿠버네티스는 하나의 노드에 여러 개의 파드가 실행되기 때문에 노드에 배정된 논리 코어를 여러 파드가 나누어 사용한다.

##### 스케일을 테스트하는 새로운 컨테이너 생성

```
FROM ubuntu:18.04
RUN apt-get update && apt-get install -y stress #(1)
ENTRYPOINT ["/usr/bin/stress"]                  #(2)
```

```cmd
$ docker build . -t my-stress:1.0.0
```

1. 컨테이너에 `apt-get`을 이용하여 `stress`를 설치한다.
2. 디플로이먼트에서 `stress`의 인자를 바꿔가며 실행할 수 있도록 `ENTRYPOINT`로 지정한다.

이 이미지는 `stress`를 이용해 인위적으로 CPU 혹은 메모리 사용량을 발생시킨다. 이 컨테이너를 활용하는 새로운 디플로이먼트를 만들어 보자.

```yaml
# chapter3/my-stress-01.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: my-stress
spec:
  replicas: 3
  selector:
    matchLabels:
      app: stress-app
  template:
    metadata:
      labels:
        app: stress-app
    spec:
      containers:
        - name: stress-generator
          image: stress:1.0.0
          args: ["--cpu", "8", "--timeout", "60s"]
```

이 디플로이먼트는 60초 동안 8코어만큼의 CPU 로드를 발생시키는 컨테이너를 가진 파드를 2개 만들어 낸다.

```
$ kubectl delete deployments my-deploy
deployment.apps "my-deploy" deleted
```

```
$ kubectl apply -f my-stress-01.yaml
deployment.apps/my-stress created
```

```
$ kubectl get pods
NAME                         READY   STATUS    RESTARTS      AGE
my-stress-5b8697647c-l8fjv   1/1     Running   3 (35s ago)   8m31s
my-stress-5b8697647c-rhzck   1/1     Running   3 (39s ago)   8m31s
```

총 4코어를 사용할 수 있는 쿠버네티스 노드에서 실행한 결과이다. 8코어의 자원을 사용하는 파드를 2개 배포했으므로 필요한 CPU 자원은 총 16코어이다. 하지만 노드가 제공할 수 있는 자원은 4코어가 전부이기에 쿠버네티스는 각각의 파드에 CPU 자원을 적당히 분배해 주었다.

여기서 알 수 있듯이 쿠버네티스의 파드는 별다른 설정이 없을 경우 자원 사용량에 제한을 두지 않는다. 그래서 부하가 많이 걸리는 작업을 수행할 경우 사용할 수 있는 노드의 자원을 모두 사용한다.

파드를 정의할 때 다음과 같이 자원 사용량을 정의해 줄 수 있다.

```yaml
# chapter3/my-stress-01.yaml (업데이트)
...(중략)...
  spec:
    containers:
    - name: stress-generator
      image: stress:1.0.0
      args: ["--cpu", "8", "--timeout", "60s"]
      resources:
        requests: # 이 자원을 실행하기 위해 필요한 최소 자원
          cpu: "500m"
          memory: "1000Mi"
        limits: # 이 파드가 사용할 수 있는 최대 자원
          cpu: "1000m"
          memory: "2000Mi"
```

```
$ kubectl apply -f my-stress-01.yaml
deployment.apps/my-stress configured
```

파드가 CPU를 점유하는 것을 전과 후로 비교해보자.

```
(before)
$ kubectl top pods
NAME                         CPU(cores)   MEMORY(bytes)
my-stress-5b8697647c-qh9vs   1688m        1Mi
my-stress-5b8697647c-sn97q   1728m        1Mi

(after)
$ kubectl top pods
NAME                        CPU(cores)   MEMORY(bytes)
my-stress-588fb75fc-f2czf   1000m        1Mi
my-stress-588fb75fc-wrkvb   1001m        1Mi
```

```
(before)
$ kubectl top nodes
top nodes
NAME             CPU(cores)   CPU%   MEMORY(bytes)   MEMORY%
docker-desktop   3991m        99%    1666Mi          21%

(after)
$ kubectl top nodes
NAME             CPU(cores)   CPU%   MEMORY(bytes)   MEMORY%
docker-desktop   2072m        51%    1657Mi          21%
```

이전과는 다르게 `limits` 에서 CPU 사용량의 상한을 1000밀리코어로 제한했으므로 노드의 모든 자원을 다 사용하지 않는다.

만약 '우리 파드는 자원을 많이 사용하므로 CPU를 넉넉히 달라'는 의미로 `requets`에 8코어의 자원을 요청한다면 어떻게 될까?

```yaml
# chapter3/my-stress-02.yaml
...(중략)...
  spec:
    containers:
    - name: stress-generator
      image: stress:1.0.0
      args: ["--cpu", "8", "--timeout", "60s"]
      resources:
        requests: # 이 자원을 실행하기 위해 필요한 최소 자원
          cpu: "500m"
          memory: "1000Mi"
        limits: # 이 파드가 사용할 수 있는 최대 자원
          cpu: "1000m"
          memory: "2000Mi"
```

```
$ kubectl apply -f my-stress-02.yaml
deployment.apps/my-stress configured
```

이후 디플로이먼트를 다시 적용하고 파드를 조회해보면 파드가 Running 상태로 전환되지 못하고 Pending 상태에 머무르는 것을 확인할 수 있다.

```
$ kubectl describe pods my-stress-7ccdb4dd46-cfc5t
...
Events:
  Type     Reason            Age                  From               Message
  ----     ------            ----                 ----               -------
  Warning  FailedScheduling  14s (x2 over 5m17s)  default-scheduler  0/1 nodes are available: 1 Insufficient cpu. preemption: 0/1 nodes are available: 1 No preemption victims found for incoming pod.
```

Insufficient cpu 라는 메시지를 통해 CPU가 부족하여 스케줄링에 실패했다는 사실을 알 수 있다. `requests`는 파드가 사용해야 하는 최소한의 자원을 정의하기 때문에 쿠버네티스는 8코어의 여유를 가진 노드에만 해당 파드를 배치해 준다. 만약 어떤 워커노드도 8코어의 여유가 없다면 파드는 실행되지 못하고 조건에 맞는 노드가 나타날 때까지 Pending 상태로 대기한다.

#### resources의 limits 와 requests

- `resources` 혹은 `limits`를 지정하지 않는 것은 일반적으로 좋은 선택은 아니다.
- `limits`을 정의하지 않는다면 배치한 상황에 따라 노드의 자원을 모두 점유하여 다른 파드들이 실행되지 못하거나 최악의 경우 일부 파드가 종료될 수 있다.

- `requests`를 정의하지 않는다면 애플리케이션의 정상 동작에 필요한 최소한의 자원도 없는 상태에서 파드가 실행되어서 초기화 작업이나 애플리케이션의 동작이 제대로 수행되지 않을 수도 있다.

- `limits`는 `requests`보다 작게 정의할 수 없으며, 만약 `limits`만 정의한다면 `requests`는 암묵적으로 `limits`와 동일하게 지정된다. 반대로 `requests`만 정의한다면 컨테이너는 제한 없이 노드의 자원을 모두 사용한다.

<br/>

사용자 금증/감소에 대비해서 파드를 스케일 업 혹은 스케일 다운을 시도하고자 한다면 사전에 정의한 파드의 `resources` 정의를 바꾸어 주는 것으로 충분히 대응할 수 있다.

실습을 위해 사용한 `my-stress` 디플로이먼트는 쿠버네티스 클러스터에 부담을 줄 수 있으니 삭제해준다.

```
$ kubectl delete deploy my-stress
```
