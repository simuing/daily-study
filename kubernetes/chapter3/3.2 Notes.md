## 파드 자원 사용량 정의하고 스케일 업하기

쿠버네티스는 하나의 노드에 여러 개의 파드가 실행되기 때문에 노드에 배정된 논리 코어를 여러 파드가 나누어 사용한다. 

##### 스케일을 테스트하는 새로운 컨테이너 생성

```
FROM ubuntu:18.04
RUN apt-get update && apt-get install -y stress #(1)
ENTRYPOINT ["/usr/bin/stress"]                  #(2)
```

```cmd
$ docker build . -t my-stress:1.0.0
```
1. 컨테이너에 `apt-get`을 이용하여 `stress`를 설치한다.
2. 디플로이먼트에서 `stress`의 인자를 바꿔가며 실행할 수 있도록 `ENTRYPOINT`로 지정한다.

이 이미지는 `stress`를 이용해 인위적으로 CPU 혹은 메모리 사용량을 발생시킨다. 이 컨테이너를 활용하는 새로운 디플로이먼트를 만들어 보자.

```yaml
# chapter3/my-stress-01.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: my-stress
spec:
  replicas: 3
  selector:
    matchLabels:
      app: stress-app
  template:
    metadata:
      labels:
        app: stress-app
    spec:
      containers:
      - name: stress-generator
        image: stress:1.0.0
        args: ["--cpu", "8", "--timeout", "60s"]
```

이 디플로이먼트는 60초 동안 8코어만큼의 CPU 로드를 발생시키는 컨테이너를 가진 파드를 2개 만들어 낸다.

```
$ kubectl delete deployments my-deploy
deployment.apps "my-deploy" deleted
```

```
$ kubectl apply -f my-stress-01.yaml 
deployment.apps/my-stress created
```

```
$ kubectl get pods
NAME                         READY   STATUS    RESTARTS      AGE
my-stress-5b8697647c-l8fjv   1/1     Running   3 (35s ago)   8m31s
my-stress-5b8697647c-rhzck   1/1     Running   3 (39s ago)   8m31s
```

총 4코어를 사용할 수 있는 쿠버네티스 노드에서 실행한 결과이다. 8코어의 자원을 사용하는 파드를 2개 배포했으므로 필요한 CPU 자원은 총 16코어이다. 하지만 노드가 제공할 수 있는 자원은 4코어가 전부이기에 쿠버네티스는 각각의 파드에 CPU 자원을 적당히 분배해 주었다.

여기서 알 수 있듯이 쿠버네티스의 파드는 별다른 설정이 없을 경우 자원 사용량에 제한을 두지 않는다. 그래서 부하가 많이 걸리는 작업을 수행할 경우 사용할 수 있는 노드의 자원을 모두 사용한다.

파드를 정의할 때 다음과 같이 자원 사용량을 정의해 줄 수 있다.
```yaml
# chapter3/my-stress-01.yaml (업데이트)
...(중략)...
  spec:
    containers:
    - name: stress-generator
      image: stress:1.0.0
      args: ["--cpu", "8", "--timeout", "60s"]
      resources:
        requests: # 이 자원을 실행하기 위해 필요한 최소 자원
          cpu: "500m"
          memory: "1000Mi"
        limits: # 이 파드가 사용할 수 있는 최대 자원
          cpu: "1000m"
          memory: "2000Mi"
```

```
$ kubectl apply -f my-stress-01.yaml
deployment.apps/my-stress configured
```

파드가 CPU를 점유하는 것을 전과 후로 비교해보자.

```
(before)
$ kubectl top pods
NAME                         CPU(cores)   MEMORY(bytes)   
my-stress-5b8697647c-qh9vs   1688m        1Mi             
my-stress-5b8697647c-sn97q   1728m        1Mi 

(after)
$ kubectl top pods
NAME                        CPU(cores)   MEMORY(bytes)   
my-stress-588fb75fc-f2czf   1000m        1Mi             
my-stress-588fb75fc-wrkvb   1001m        1Mi  
```

```
(before)
$ kubectl top nodes
top nodes
NAME             CPU(cores)   CPU%   MEMORY(bytes)   MEMORY%   
docker-desktop   3991m        99%    1666Mi          21% 

(after)
$ kubectl top nodes
NAME             CPU(cores)   CPU%   MEMORY(bytes)   MEMORY%   
docker-desktop   2072m        51%    1657Mi          21%  
```

이전과는 다르게 `limits` 에서 CPU 사용량의 상한을 1000밀리코어로 제한했으므로 노드의 모든 자원을 다 사용하지 않는다. 

만약 '우리 파드는 자원을 많이 사용하므로 CPU를 넉넉히 달라'는 의미로 `requets`에 8코어의 자원을 요청한다면 어떻게 될까?

```yaml
# chapter3/my-stress-02.yaml
...(중략)...
  spec:
    containers:
    - name: stress-generator
      image: stress:1.0.0
      args: ["--cpu", "8", "--timeout", "60s"]
      resources:
        requests: # 이 자원을 실행하기 위해 필요한 최소 자원
          cpu: "500m"
          memory: "1000Mi"
        limits: # 이 파드가 사용할 수 있는 최대 자원
          cpu: "1000m"
          memory: "2000Mi"
```

```
$ kubectl apply -f my-stress-02.yaml
deployment.apps/my-stress configured
```